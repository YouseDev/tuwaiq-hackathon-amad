interface LLMResponse {
    type: "info" | "action" | "ignore"
    fillerAudio?: string
    response: string
    needsOTP?: boolean
    actionData?: any
}

interface BankingContext {
    user: any
    accounts: any
    creditCards: any[]
    transactions: any[]
    bills: any[]
    contacts: any[]
}

class LLMService {
    private static instance: LLMService
    private apiKey: string

    static getInstance(): LLMService {
        if (!LLMService.instance) {
            LLMService.instance = new LLMService()
        }
        return LLMService.instance
    }

    constructor() {
        this.apiKey = process.env.EXPO_PUBLIC_OPENAI_KEY || ""
    }

    async processUserQuery(
        userInput: string,
        bankingContext: BankingContext,
    ): Promise<LLMResponse> {
        if (!this.apiKey) {
            return {
                type: "ignore",
                response: "Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹",
            }
        }

        // LLM will handle echo keyword verification
        const startTime = Date.now()

        try {
            const prompt = this.buildPrompt(userInput, bankingContext)
            console.log("ğŸ§  Sending to OpenAI:", userInput)

            const response = await fetch(
                "https://api.openai.com/v1/chat/completions",
                {
                    method: "POST",
                    headers: {
                        Authorization: `Bearer ${this.apiKey}`,
                        "Content-Type": "application/json",
                    },
                    body: JSON.stringify({
                        model: "gpt-4.1",
                        messages: [
                            {
                                role: "system",
                                content: prompt,
                            },
                            {
                                role: "user",
                                content: userInput,
                            },
                        ],
                    }),
                },
            )

            const apiTime = Date.now() - startTime
            console.log(`â±ï¸ OpenAI API took: ${apiTime}ms`)

            if (!response.ok) {
                const errorText = await response.text()
                console.error(
                    `âŒ OpenAI API error ${response.status}:`,
                    errorText,
                )
                throw new Error(`OpenAI API error: ${response.status}`)
            }

            const data = await response.json()
            console.log("ğŸ” Full API Response:", JSON.stringify(data, null, 2))

            const llmOutput = data.choices[0]?.message?.content

            if (!llmOutput) {
                console.error(
                    "âŒ No content in response. Data structure:",
                    data,
                )
                throw new Error("No response from OpenAI")
            }

            console.log("ğŸ” Raw LLM Output:", llmOutput)

            // Parse JSON response from LLM
            let parsedResponse: LLMResponse
            try {
                parsedResponse = JSON.parse(llmOutput)
            } catch (parseError) {
                console.error(
                    "âŒ Failed to parse LLM JSON response:",
                    parseError,
                )
                console.error(
                    "âŒ Raw response that failed to parse:",
                    llmOutput,
                )
                throw new Error("Invalid JSON response from LLM")
            }

            const totalTime = Date.now() - startTime
            console.log(`âœ… LLM Complete - Total time: ${totalTime}ms`)
            console.log("ğŸ“‹ LLM Response:", {
                type: parsedResponse.type,
                fillerAudio: parsedResponse.fillerAudio,
                response: parsedResponse.response,
                needsOTP: parsedResponse.needsOTP,
            })

            return parsedResponse
        } catch (error) {
            const totalTime = Date.now() - startTime
            console.error(`âŒ LLM Service error after ${totalTime}ms:`, error)
            return {
                type: "ignore",
                response: "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ",
            }
        }
    }

    private buildPrompt(userInput: string, context: BankingContext): string {
        return `You are "Echo", a smart Saudi banking assistant for a Bank. Respond in Saudi Arabic dialect, casual but professional.
      
      COMPLETE USER DATA:
      User Info: ${JSON.stringify(context.user, null, 2)}
      Accounts: ${JSON.stringify(context.accounts, null, 2)}
      Credit Cards: ${JSON.stringify(context.creditCards, null, 2)}
      Recent Transactions: ${JSON.stringify(context.transactions.slice(0, 10), null, 2)}
      Bills: ${JSON.stringify(context.bills, null, 2)}
      Contacts: ${JSON.stringify(context.contacts, null, 2)}
      
      RESPONSE RULES:
      1. For info queries (balance, transactions, cards) use "type":"info".
      2. For actions (transfers, bill payments) use "type":"action" and set "needsOTP":true.
      3. Keep answers SHORT and CONCISE (â‰¤ 2 sentences).
      4. **Write all numbers fully in Arabic words, not digits**  
         â€¢ Example: "Ù…Ø¦Ø© Ø±ÙŠØ§Ù„" âœ… â€” not "100 Ø±ÙŠØ§Ù„" âŒ
      5. Use the exact data provided; no assumptions. Mention names & amounts explicitly.
      6. Remain casual yet professional in the Saudi dialect.
      
      FILLER AUDIO KEYS:
      - "checking_balance"(balance queries)
      - "checking_transactions" (transaction history)
      - "processing_request"(general)
      - "preparing_transfer"(transfers / payments)
      
      RESPONSE EXAMPLES (WITH WORDS, NOT DIGITS):
      - Balance: "Ø±ØµÙŠØ¯Ùƒ Ø§Ù„Ø¬Ø§Ø±ÙŠ Ø®Ù…Ø³Ø© Ø¢Ù„Ø§Ù ÙˆÙ…Ø¦ØªØ§Ù† ÙˆØ³ØªØ© ÙˆØ³ØªÙˆÙ† Ø±ÙŠØ§Ù„ØŒ ÙˆØ§Ù„ØªÙˆÙÙŠØ± Ø§Ø«Ù†Ø§ Ø¹Ø´Ø± Ø£Ù„ÙÙ‹Ø§ ÙˆØ«Ù…Ø§Ù†Ù…Ø¦Ø© ÙˆØ®Ù…Ø³ÙˆÙ† Ø±ÙŠØ§Ù„."
      - Spending: "ØµØ±ÙØª Ù…Ø¦ØªÙŠÙ† ÙˆØ³ØªÙŠÙ† Ø±ÙŠØ§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ù‡Ø§Ù„Ø´Ù‡Ø± ÙÙŠ Ø®Ù…Ø³ Ù…Ø¹Ø§Ù…Ù„Ø§Øª."
      - Bills: "Ø¹Ù†Ø¯Ùƒ Ø«Ù„Ø§Ø« ÙÙˆØ§ØªÙŠØ± Ù…Ø³ØªØ­Ù‚Ø©: Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¡ Ù…Ø¦ØªØ§Ù† ÙˆØ®Ù…Ø³Ø© ÙˆØ«Ù…Ø§Ù†ÙˆÙ† Ø±ÙŠØ§Ù„ØŒ Ø§Ù„Ù…ÙŠØ§Ù‡ Ø®Ù…Ø³Ø© ÙˆØªØ³Ø¹ÙˆÙ† Ø±ÙŠØ§Ù„ØŒ Ø²ÙŠÙ† Ù…Ø¦Ø© ÙˆØ®Ù…Ø³Ø© ÙˆØ¹Ø´Ø±ÙˆÙ† Ø±ÙŠØ§Ù„."
      
      ALWAYS reply in this exact JSON schema:
      {
        "type": "info" | "action" | "ignore",
        "fillerAudio": "audio_key",
        "response": "short Arabic response",
        "needsOTP": false,
        "actionData": {}
      }`
    }

    static isConfigured(): boolean {
        const instance = LLMService.getInstance()
        return !!instance.apiKey
    }
}

export default LLMService.getInstance()
